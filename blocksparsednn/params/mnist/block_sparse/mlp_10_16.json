{
    "name": "block_sparse_mlp",
    "num_epochs": 50,
    "hidden_units": [256, 256, 16],
    "block_size": 16,
    "sparsity": 0.39,
    "prune_fraction": 0.05,
    "hidden_activation": "relu",
    "dropout_keep_rate": 1.0,
    "l2": 0.01
}
