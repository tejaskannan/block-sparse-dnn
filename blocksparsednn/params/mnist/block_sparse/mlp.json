{
    "name": "block_sparse_mlp",
    "num_epochs": 10,
    "hidden_units": [64, 64, 16],
    "block_size": 16,
    "sparsity": 0.5,
    "prune_fraction": 0.1,
    "hidden_activation": "relu",
    "dropout_keep_rate": 1.0,
    "l2": 0.1
}
