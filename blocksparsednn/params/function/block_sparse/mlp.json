{
    "name": "block_sparse_mlp",
    "num_epochs": 2,
    "hidden_units": [24, 24, 12],
    "block_size": 6,
    "sparsity": 1.0,
    "prune_fraction": 0.1,
    "hidden_activation": "leaky_relu",
    "dropout_keep_rate": 1.0,
    "l2": 0.01
}
