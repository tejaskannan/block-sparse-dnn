{
    "name": "rnn",
    "batch_size": 128,
    "learning_rate": 0.001,
    "learning_rate_decay": 0.99,
    "gradient_clip": 1,
    "num_epochs": 25,
    "patience": 25,
    "state_size": 128,
    "rnn_layers": 2,
    "hidden_units": [256, 256],
    "hidden_activation": "leaky_relu",
    "optimizer": "adam",
    "dropout_keep_rate": 0.8,
    "should_layer_normalize": true,
    "should_normalize_inputs": false,
    "dataset_type": "memory"
}
